
<!DOCTYPE html>
<html lang="en" data-figures="" class="page" data-mode="dim">
  <head>
<title>Text Analysis with R | Clarity</title>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.80.0" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<script async src="https://www.googletagmanager.com/gtag/js?id=XXXXXXXXXX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'XXXXXXXXXX');
</script>
  
<meta property="og:locale" content="en" />

<meta property="og:type" content="article">
<meta name="description" content="Recently I found myself with some free time on my hands so I decided to learn a new skill, or at least start learning. So I thought to myself, what would be a ‚Ä¶">
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:creator" content="@AluasVlad">
<meta name="twitter:title" content="Text Analysis with R" />
<meta property="og:url" content="https://www.vladaluas.com/post/text-analysis-with-r/" />
<meta property="og:title" content="Text Analysis with R" />
<meta property="og:description" content="Recently I found myself with some free time on my hands so I decided to learn a new skill, or at least start learning. So I thought to myself, what would be a ‚Ä¶" />
<meta property="og:image" content="https://www.vladaluas.com/images/WordCloud.png" />
<link rel="apple-touch-icon" sizes="180x180" href='https://www.vladaluas.com/icons/apple-touch-icon.png'>
<link rel="icon" type="image/png" sizes="32x32" href='https://www.vladaluas.com/icons/favicon-32x32.png'>
<link rel="manifest" href='https://www.vladaluas.com/icons/site.webmanifest'>
<link rel="mask-icon" href='https://www.vladaluas.com/safari-pinned-tab.svg' color="#002538">
<meta name="msapplication-TileColor" content="#002538">
<meta name="theme-color" content="#002538">

<link rel="canonical" href="https://www.vladaluas.com/post/text-analysis-with-r/">

    

    
    
    <link rel="preload" href="https://www.vladaluas.com/css/styles.782bf96a82b3cc5b3cee4c47a42cc81321f16960a6d41fab3277c4abe047bc7ae044ea1bb7ae4d237c12baa0143e02f95969e5e8b6e68d9dcfd14158cfa244ac.css" integrity = "sha512-eCv5aoKzzFs87kxHpCzIEyHxaWCm1B&#43;rMnfEq&#43;BHvHrgROobt65NI3wSuqAUPgL5WWnl6LbmjZ3P0UFYz6JErA==" as="style" crossorigin="anonymous">
    <link rel="preload" href="https://www.vladaluas.com/js/bundle.min.d9c61e439fe5301e875d687a930ef57eb7e61e43791740d42a373b51acdb4b76c8a13828486c9b18aeccd221941642bcbf68a751076c32b08f874a64cf11d7f0.js" as="script" integrity=
    "sha512-2cYeQ5/lMB6HXWh6kw71frfmHkN5F0DUKjc7UazbS3bIoTgoSGybGK7M0iGUFkK8v2inUQdsMrCPh0pkzxHX8A==" crossorigin="anonymous">

    
    <link rel="stylesheet" type="text/css" href="https://www.vladaluas.com/css/styles.782bf96a82b3cc5b3cee4c47a42cc81321f16960a6d41fab3277c4abe047bc7ae044ea1bb7ae4d237c12baa0143e02f95969e5e8b6e68d9dcfd14158cfa244ac.css" integrity="sha512-eCv5aoKzzFs87kxHpCzIEyHxaWCm1B&#43;rMnfEq&#43;BHvHrgROobt65NI3wSuqAUPgL5WWnl6LbmjZ3P0UFYz6JErA==" crossorigin="anonymous">
    
  </head>
  
  
    
  
  <body data-code="2" data-lines="false" id="documentTop">

<header class="nav_header" >
  <nav class="nav"><a href='https://www.vladaluas.com/' class="nav_brand nav_item" title="Clarity">
  <img src="https://www.vladaluas.com/logos/logo.png" class="logo" alt="Clarity">
  <div class="nav_close">
    <div><svg class="icon">
  <use xlink:href="#open-menu"></use>
</svg><svg class="icon">
  <use xlink:href="#closeme"></use>
</svg></div>
  </div>
</a>
    <div class='nav_body nav_body_left'>
      
      
      
        

  <div class="nav_parent">
    <a href="https://www.vladaluas.com/" class="nav_item" title="Home">Home </a>
  </div>
  <div class="nav_parent">
    <a href="https://www.vladaluas.com/post/rich-content/" class="nav_item" title="Archives">Archives </a>
  </div>
  <div class="nav_parent">
    <a href="https://www.vladaluas.com/" class="nav_item" title="Links">Links <img src='https://www.vladaluas.com/icons/caret-icon.svg' alt="icon" class="nav_icon"></a>
    <div class="nav_sub">
      <span class="nav_child"></span>
        <a href="https://www.linkedin.com/" class="nav_child nav_item" title="LinkedIn">LinkedIn</a>
        <a href="https://twitter.com/" class="nav_child nav_item" title="Twitter">Twitter</a>
    </div>
  </div>
  <div class="nav_parent">
    <a href="https://www.vladaluas.com/about/" class="nav_item" title="About">About </a>
  </div>
      
      <div class="nav_parent">
        <a href="#" class="nav_item">üåê</a>
        <div class="nav_sub">
          <span class="nav_child"></span>
          
          <a href="https://www.vladaluas.com/" class="nav_child nav_item">English</a>
          
          <a href="https://www.vladaluas.com/pt/" class="nav_child nav_item"></a>
          
        </div>
      </div>
<div class='follow'>
  <a href="https://github.com/#">
    <svg class="icon">
  <use xlink:href="#github"></use>
</svg>
  </a>
  <a href="https://twitter.com/#">
    <svg class="icon">
  <use xlink:href="#twitter"></use>
</svg>
  </a>
  <a href="https://www.linkedin.com/in/#">
    <svg class="icon">
  <use xlink:href="#linkedin"></use>
</svg>
  </a>
    
  <a href="https://www.vladaluas.com/index.xml">
    <svg class="icon">
  <use xlink:href="#rss"></use>
</svg>
  </a>
<div class="color_mode">
  <input type="checkbox" class="color_choice" id="mode">
</div>

</div>

    </div>
  </nav>
</header>

    <main>
  
<div class="grid-inverse wrap content">
  <article class="post_content">
    <h1 class="post_title">Text Analysis with R</h1><div class="post_meta">
  
    <svg class="icon">
  <use xlink:href="#calendar"></use>
</svg>
    <span class="post_date">
      10 Feb 2021</span>
      <a href='https://www.vladaluas.com/tags/text-analysis' title="text analysis" class="post_tag button button_translucent">text analysis
      </a>
      <a href='https://www.vladaluas.com/tags/r' title="R" class="post_tag button button_translucent">R
      </a>
      <a href='https://www.vladaluas.com/tags/tidyverse' title="tidyverse" class="post_tag button button_translucent">tidyverse
      </a>
      <a href='https://www.vladaluas.com/tags/tidytext' title="tidytext" class="post_tag button button_translucent">tidytext
      </a>
</div>

    
  <div class="post_share">
    Share on:
    <a href="https://twitter.com/intent/tweet?text=Text%20Analysis%20with%20R&url=https%3a%2f%2fwww.vladaluas.com%2fpost%2ftext-analysis-with-r%2f&tw_p=tweetbutton" class="twitter" title="Share on Twitter" target="_blank" rel="nofollow">
      <svg class="icon">
  <use xlink:href="#twitter"></use>
</svg>
    </a>
    <a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fwww.vladaluas.com%2fpost%2ftext-analysis-with-r%2f&t=Text%20Analysis%20with%20R" class="facebook" title="Share on Facebook" target="_blank" rel="nofollow">
      <svg class="icon">
  <use xlink:href="#facebook"></use>
</svg>
    </a>
    <a href="#linkedinshare" id = "linkedinshare" class="linkedin" title="Share on LinkedIn" rel="nofollow">
      <svg class="icon">
  <use xlink:href="#linkedin"></use>
</svg>
    </a>
    <a href="https://www.vladaluas.com/post/text-analysis-with-r/" title="Copy Link" class="link link_yank">
      <svg class="icon">
  <use xlink:href="#copy"></use>
</svg>
    </a>
  </div>

    
    
<script src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/header-attrs/header-attrs.js"></script>


<p></br></p>
<p><strong>Recently I found myself with some free time on my hands so I decided to learn a new skill, or at least start learning. So I thought to myself, what would be a good skill that would help me as a data analyst or would have helped me in the past? It had to be something that took a lot of time and that could be automated.</strong></p>
<hr />
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Recently I found myself with some free time on my hands so I decided to learn a new skill, or at least start learning. So I thought to myself, what would be a good skill that would help me as a data analyst or would have helped me in the past? It had to be something that took a lot of time and that could be automated.</p>
<p>And then it struck me, <strong>TEXT ANALYSIS!</strong></p>
<p>I always hated the annoying task of having to analyse text, be it in the form of comments on the internet, transcripts from focus groups or something else, does not matter. As you might know, if you‚Äôve done this sort of analysis, this can be a really boring and tedious work and can take a large amount of time. The way I used to do it was to read the comments, categorize each one then do some basic analysis based on those categories.</p>
<p>You can avoid spending the huge amount of time on this situation if you learn how to analyse text using a programming language and here is why. You can be required to analyse text either as a recurring report or as a one time analysis. In both cases text analysis can be very beneficial.</p>
<p>In the first case is kind of self-explanatory. You need to spend the time to set up the analysis, graphs and report, but this needs to be done just once and you can use it every time you want to refresh the report. The other solution is to analyse the data manually every time.</p>
<p>Now, what about the second case, when you have a one time report? Wouldn‚Äôt it take just as much time to set up the report as it would to analyse it manually? Well, no and you will see in the article below how easy it can be to analyse data using <code>R</code>.</p>
<p>So, in order to see how to analyse text using <code>R</code> I have started reading <a href="https://www.tidytextmining.com/index.html"><strong>Text Mining with R</strong></a> by <em>Julia Silge</em> and <em>David Robinson</em>. I highly recommend this book as their approach is to transform the text into a tidy format that allows you to easily analyse and visualize the results using graphs.</p>
</div>
<div id="disclaimers-and-the-structure" class="section level1">
<h1>Disclaimers and the structure</h1>
<p>I would like to shortly discuss the structure of the article and make some disclaimers about it, so we are on the same page.</p>
<p>This article is intended just as an introductory example into what text analysis can do and how it can be used by data analysts, although I encourage you to study further if you think these methods can be useful. It is not intended as a comprehensive course on Natural Language Processing (NLP), as that is a complex topic that cannot be dealt with in just one article. Here, I will just show you three methods that can cover a great deal of analytical needs in a company.</p>
<p>I would also like to point out that I will show some basic sentiment analysis methods, however they do not cover all the possibilities and are just the tip of the iceberg. That being said, with some tweaking, they can reliably be used as a starting point in the endeavours to automate this process, with more complex methods being added at a latter time.</p>
<p>So, with the disclaimers out of the way we will discuss:</p>
<ul>
<li>Word Frequencies</li>
<li>Comparisons Between Texts</li>
<li>Sentiment Analysis</li>
<li>Wordclouds</li>
</ul>
</div>
<div id="the-data" class="section level1">
<h1>The Data</h1>
<p>As a dataset, I though that a series of phone reviews would be a good starting point.</p>
<p>As an analyst, it might be required of you to spend some time analysing reviews for different products your company makes and get insight from said reviews. As a dummy dataset I have chosen a series of reviews for the <strong>OnePlus</strong> phone models. You can check the reviews <a href="https://www.pcmag.com/categories/mobile-phones/brands/oneplus">here</a>.</p>
<p>I could have chosen any other brand of phone, or any other product for that matter, however I own a <strong>OnePlus</strong>. I want to check what is the general opinion about them and see if my decision was right or was it just bias.</p>
<p>See, these text analysis skills can be used for selfish reasons as well, it doesn‚Äôt always have to be something <em>‚Äúuseful‚Äù</em> or <em>‚Äúproductive‚Äù</em>. You can learn them just so you can allow yourself to be too lazy to read a book or a review front to back.</p>
<p>Now let‚Äôs download the data.</p>
<pre class="r"><code># We will need a URL from where to download the data
# In this case we will do it from my GitHub repository
# You can download the data using this link
url &lt;- &quot;https://raw.github.com/VladAluas/Text_Analysis/master/Datasets/Text_review.csv&quot;


# I prefer vroom to ingest csv, but you can use readr::read_csv() if you fancy it more
reviews &lt;- vroom::vroom(url)</code></pre>
<pre><code>#&gt; Rows: 433
#&gt; Columns: 3
#&gt; Delimiter: &quot;,&quot;
#&gt; chr [3]: Model, Segment, Text
#&gt; 
#&gt; Use `spec()` to retrieve the guessed column specification
#&gt; Pass a specification to the `col_types` argument to quiet this message</code></pre>
<p></br></p>
<p>The structure of the data can be seen below:</p>
<pre class="r"><code>head(reviews)</code></pre>
<pre><code>#&gt; # A tibble: 6 x 3
#&gt;   Model    Segment                Text                                          
#&gt;   &lt;chr&gt;    &lt;chr&gt;                  &lt;chr&gt;                                         
#&gt; 1 OnePlus~ Introduction           &quot;The days of the $600 smartphone aren&#39;t over ~
#&gt; 2 OnePlus~ Design, Features, and~ &quot;The OnePlus One doesn&#39;t feel like a sub-$400~
#&gt; 3 OnePlus~ Design, Features, and~ &quot;Our white test unit features a so-called sil~
#&gt; 4 OnePlus~ Design, Features, and~ &quot;The 5.5-inch, 1080p IPS display is on par wi~
#&gt; 5 OnePlus~ Design, Features, and~ &quot;There are two speaker grilles flanking the m~
#&gt; 6 OnePlus~ Design, Features, and~ &quot;With GSM (850/900/1800/1900MHz), UMTS (Bands~</code></pre>
<p></br></p>
<p>As you can see, the data is structured in three columns: the model number, the segment of the review and the text from the segment.</p>
<p>I have chosen to keep each paragraph from each review as a separate text because it‚Äôs easier to work with, and it‚Äôs more realistic. This is most likely how you might analyse the data when you read and compare the reviews section by section.</p>
<p>Now that we have the data, I want to discuss the text analysis principles that I will use in this article.</p>
</div>
<div id="text-analysis" class="section level1">
<h1>Text Analysis</h1>
<p>As you can see, it is quite hard to work with the data at the moment. You can‚Äôt count words or quantify them in any way, so we will need to transform the last column into a more analysis friendly format.</p>
<p>As mentioned in the introduction, we will use some methods developed by <em>Julia Silge</em> and <em>David Robinson</em> in the <code>tidytext</code> package. The function that we will <em>‚Äúabuse‚Äù</em> in this article is <code>unnest_tokens()</code>.</p>
<p>This function allows us to transform the text column into a <strong>tidy</strong> format (see <a href="https://vita.had.co.nz/papers/tidy-data.pdf">here</a>).</p>
<p>Let‚Äôs see it in action.</p>
<pre class="r"><code># We need to activate some additional libraries
# If you do not have the libraries installed you can install them using: install.packages(c(&quot;tidyverse&quot;, &quot;tidytext&quot;))
library(tidytext)
library(tidyverse)</code></pre>
<pre><code>#&gt; Registered S3 methods overwritten by &#39;readr&#39;:
#&gt;   method           from 
#&gt;   format.col_spec  vroom
#&gt;   print.col_spec   vroom
#&gt;   print.collector  vroom
#&gt;   print.date_names vroom
#&gt;   print.locale     vroom
#&gt;   str.col_spec     vroom</code></pre>
<pre><code>#&gt; -- Attaching packages --------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>#&gt; v ggplot2 3.3.3     v purrr   0.3.4
#&gt; v tibble  3.0.6     v dplyr   1.0.4
#&gt; v tidyr   1.1.2     v stringr 1.4.0
#&gt; v readr   1.4.0     v forcats 0.5.1</code></pre>
<pre><code>#&gt; -- Conflicts ------------------------------------------ tidyverse_conflicts() --
#&gt; x dplyr::filter() masks stats::filter()
#&gt; x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>reviews %&gt;%
# We need to specify the name of the column to be created (Word) and the source column (Text)
  unnest_tokens(&quot;Word&quot;, &quot;Text&quot;) </code></pre>
<pre><code>#&gt; # A tibble: 30,067 x 3
#&gt;    Model     Segment      Word      
#&gt;    &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;     
#&gt;  1 OnePlus 1 Introduction the       
#&gt;  2 OnePlus 1 Introduction days      
#&gt;  3 OnePlus 1 Introduction of        
#&gt;  4 OnePlus 1 Introduction the       
#&gt;  5 OnePlus 1 Introduction 600       
#&gt;  6 OnePlus 1 Introduction smartphone
#&gt;  7 OnePlus 1 Introduction aren&#39;t    
#&gt;  8 OnePlus 1 Introduction over      
#&gt;  9 OnePlus 1 Introduction quite     
#&gt; 10 OnePlus 1 Introduction yet       
#&gt; # ... with 30,057 more rows</code></pre>
<p>As you can see, the function took all the sentences from the <strong>Text</strong> column and broke them down into a format that has one word per row and way more rows than before. So, our new data structure is one step away from a tidy format, all we need to do is count each word to see how many times it appears in the text, and then we will have a tidy format.</p>
<p>I would also like to point out, as you have already probably noticed, that the function has transformed all the words to lower case and removed all the special symbols (<em>e.g.</em> the $ from the price described in the introduction of the <strong>OnePlus 1</strong>). This is important because it can save us a lot of headaches when cleaning the data.</p>
<p>Now we will transform the data in a proper tidy format. To do so, we will <code>unnest</code> the sentences, we will count each word, and then we can display the frequencies on a graph.</p>
<p>Because we want to use the graph later, we will create a function, <code>word_frequency()</code> that contains all the steps we want to apply to the graph. We will also replace some characters, so we will not double or under count some words.</p>
<pre class="r"><code>reviews_tidy &lt;- reviews %&gt;%
  unnest_tokens(&quot;Word&quot;, &quot;Text&quot;) %&gt;%
# We also want to prevent the analysis in showing 6t and 6t&#39;s as two separate words
  mutate(Word = str_replace(Word, &quot;&#39;s&quot;, &quot;&quot;))
# We want to display graphically a word frequency plot
# We will create a function that will store all the operations we will repeat several times
word_frequency &lt;- function(x, top = 10){
  
  x %&gt;%
    
# We need a word count
  count(Word, sort = TRUE) %&gt;%
  
# We want to create a factor from the word column with the levels showing the most frequent words as top level
# This is just for aestethic reasons, however, it helps make the point
  mutate(Word = factor(Word, levels = rev(unique(Word)))) %&gt;% 
# We use the &quot;top&quot; variable defined in the function so we can decide how many words we want to use 
  top_n(top) %&gt;%
    
# This will be useful later if we want to use a grouping variable and will do nothing if we don&#39;t  
  ungroup() %&gt;%
  
# The graph itself
  ggplot(mapping = aes(x = Word, y = n)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(x = NULL)
}

reviews_tidy %&gt;%
  word_frequency(15)</code></pre>
<pre><code>#&gt; Selecting by n</code></pre>
<p><img src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/figure-html/tidy_data_with_stop-1.png" width="100%" /></p>
<p>There, frequency analysis done. Now, what does the word <strong>the</strong> say about the <strong>OnePlus</strong> brand of phones?</p>
<p><strong>Nothing!</strong></p>
<p>As you can see and might have expected, determiners and conjunctions (<em>e.g.</em> the, and, a, to) are the most frequently used words in any language and do not tell us much about the message of a sentence, not by themselves at least. These are called stop words, and we will eliminate them, so we can focus on the words that can give us a better picture of the text.</p>
<p>Fortunately for us, the <code>tidytext</code> package provides a dataset called <code>stop_words</code> (what else) that contains a list of all the determiners and conjunctions, adverbs and adjectives that we can eliminate from a text, so we can analyse it properly.</p>
<blockquote>
<p>This dataset contains only stop words from English. If you analyse a different language, you would have to use a different dataset or create one for yourself.</p>
</blockquote>
<p>With that in mind, I think we can recreate the previous graph after we eliminate the stop words and see what it tells us about the <strong>OnePlus</strong> phones overall.</p>
<pre class="r"><code># Same dataset as before with an extra code line
reviews_tidy &lt;- reviews %&gt;%
  unnest_tokens(&quot;Word&quot;, &quot;Text&quot;) %&gt;%
  anti_join(stop_words, by = c(&quot;Word&quot; = &quot;word&quot;)) %&gt;% # anti_join just keeps the rows common to both data sets
  mutate(Word = str_replace(Word, &quot;&#39;s&quot;, &quot;&quot;))
# The graph is the same as before, we just changed the dataset
reviews_tidy %&gt;%
  word_frequency(15)</code></pre>
<pre><code>#&gt; Selecting by n</code></pre>
<p><img src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/figure-html/tidy_data_without_stop-1.png" width="100%" /></p>
<p>Slightly better, don‚Äôt you think?</p>
<p>So, as an overall idea, we can see that the brand name (<strong>OnePlus</strong>) is the most used, as we would expect. Then, we can see <em>phone</em>, which is to be expected since we are talking about a product that is a phone.</p>
<p>We can also see that <em>galaxy</em> is mentioned quite a lot, just as much as <em>camera</em> which is again expected. <strong>OnePlus</strong> promoted themselves as a brand with high performance models at a cheaper price than a flagship from <strong>Samsung</strong> or other makers, therefore it would be only natural to see the comparison between the two.</p>
<p>However, if you reverse the analysis, you might not see <strong>OnePlus</strong> in a <strong>Samsung</strong> review because <strong>Samsung</strong> is the <strong>gold standard</strong> against which everyone is compared, while <strong>OnePlus</strong> is not.</p>
<p>Another pairing we see is <em>low</em> and <em>light</em> which is the part in the reviews where they are comparing camera performance in low light.</p>
<p>Also you might have spotted that <em>7</em> and <em>8</em> are there as well. This is most likely because the <em>7</em> from all the <strong>OnePlus 7</strong> series is mentioned quite a lot, the same goes for the <em>8</em>. This can be avoided, but it requires an extra step.</p>
<p>You will need to replace the spaces in the model name (<em>e.g.</em> <code>mutate(Word = str_replace(Word, "OnePlus 7", "OnePlus_7))</code>), and do this for all the models not just <strong>OnePlus 7</strong></p>
<p>I will not do this, but you are welcome to try and let me know how the analysis changed.</p>
<p>Now, the graph we used earlier shows us the most frequently used words across all texts in the corpus. This is useful because it gives us some good insight on what are the words most associated with <strong>OnePlus</strong> as a brand overall.</p>
<p>But, I would also like to have the top 5 words associated with each model. We can do so by adding two lines of code to the previous chunk. It‚Äôs as simple as:</p>
<pre class="r"><code>reviews_tidy %&gt;%
  group_by(Model) %&gt;% 
  word_frequency(5) +
  facet_wrap(~ Model, scales = &quot;free_y&quot;) # This is just to split the graph into multiple graphs for each model</code></pre>
<pre><code>#&gt; Selecting by n</code></pre>
<p><img src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/figure-html/word_frequency_facet_wrap-1.png" width="100%" /></p>
<p>Cool, right?</p>
<p>We have a matrix of graphics that shows us which terms are most frequently associated with a model and that is very useful from a business perspective. Although, keep in mind that these terms might require some cleaning. You might have words that are not useful for your analysis.</p>
<p>There might be some cases in which you have a known fault in your product and it can be so frequent that it overshadows every other feedback. In this particular case an example can be the word <strong>oneplus</strong>. This word has no relevance to the analysis, we know the name of the brand we are interested in, and having this word in the graphs might obscure the presence of a more relevant word.</p>
<p>It can be anything else, let‚Äôs say a battery problem, you name it, I‚Äôm sure you have your own example in mind.</p>
<p>Should that be the case, there is a simple solution for that. Add the undesired words to the <code>stop_words</code> list and start the analysis all over again and it will give you the most frequent words that are of interest.</p>
<p>I would suggest using this very sparsely, as you might overlook some crucial information that at some point seemed unimportant and now you forgot that is forcefully removed.</p>
</div>
<div id="comparison-between-models" class="section level1">
<h1>Comparison between models</h1>
<p>That is all well and good, but in the end, we still have to analyse the graphs using our instincts and determine what is the conclusion for each model, right? This cannot be automated!</p>
<p><strong>Yes, it can!!!</strong></p>
<p>For our purpose we will use a method called <strong>Term frequency - inverse document frequency</strong> (<strong>tf_idf</strong> for short and the fact that it rolls off the tongue easier). You can read more about this <a href="https://www.tidytextmining.com/tfidf.html#zipfs-law">here</a>, but I will also give you a <strong>TL;DR</strong> here.</p>
<p>As you could see in the first graph, the most frequent terms in the review are the ones with no analytical value whatsoever, <em>the</em>, <em>and</em>, <em>a</em>, <em>etc</em>. Words that have a high analytical value (<em>e.g.</em> performance) will appear less often.</p>
<p>Kepping that in mind, the <strong>tf_idf</strong> method works based on this principle something like this. The word <em>oneplus</em> is in all reviews so that does not tell us anything about a particular document. The model number on the other hand, is specific for each review and therefore way more important in helping us distinguish between the document. The same can go for the top tier rival phone models to <strong>OnePlus</strong> at the time of the review (<em>e.g.</em> <strong>Galaxy S20</strong>).</p>
<p>This can be used to our advantage with a bit of a twist. We can check for the words that are frequent in one review and not the others to see what distinguishes one document from another.</p>
<p>This comparison can be done with a simple formula <code>bind_tf_idf()</code> that assigns weights to words using the principles below:</p>
<ul>
<li>words with high frequency in all the documents: <strong>low weight</strong></li>
<li>words with high frequency in just one of the documents and not the other: <strong>high weight</strong></li>
<li>words with low frequency across the board: <strong>low weight</strong></li>
</ul>
<p>Let‚Äôs see this in practice:</p>
<pre class="r"><code>review_tf_idf &lt;- 
  reviews_tidy %&gt;%
    count(Model, Word, sort = TRUE) %&gt;%
    bind_tf_idf(Word, Model, n)
review_tf_idf %&gt;%
  arrange(desc(tf_idf))</code></pre>
<pre><code>#&gt; # A tibble: 8,213 x 6
#&gt;    Model              Word        n     tf   idf tf_idf
#&gt;    &lt;chr&gt;              &lt;chr&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
#&gt;  1 OnePlus 6T         6t         31 0.0293 2.08  0.0609
#&gt;  2 OnePlus 5T         5t         21 0.0195 2.77  0.0540
#&gt;  3 OnePlus 6          s9         18 0.0183 2.77  0.0508
#&gt;  4 OnePlus 7T McLaren mclaren    20 0.0292 1.67  0.0489
#&gt;  5 OnePlus 2          s6         11 0.0164 2.77  0.0456
#&gt;  6 OnePlus 7 Pro 5G   5g         40 0.0620 0.693 0.0430
#&gt;  7 OnePlus 7T         7t         22 0.0306 1.39  0.0425
#&gt;  8 OnePlus 8 Pro      s20        25 0.0245 1.67  0.0410
#&gt;  9 OnePlus 8          s20        25 0.0223 1.67  0.0373
#&gt; 10 OnePlus 3T         3t         21 0.0222 1.67  0.0372
#&gt; # ... with 8,203 more rows</code></pre>
<p>Now we can display this using plots.</p>
<pre class="r"><code>review_tf_idf %&gt;%
  
# We need to sort the data in descending order so we can create the factors for each term
  arrange(desc(tf_idf)) %&gt;%
# We create the factors as we did previously
  mutate(Word = factor(Word, levels = rev(unique(Word)))) %&gt;%
# Select just the top 5 words for each model
  group_by(Model) %&gt;%
  top_n(5) %&gt;%
  ungroup() %&gt;%
# Our Plot
  ggplot(mapping = aes(x = Word, y = tf_idf, fill = Model)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = NULL) +
  coord_flip() +
  facet_wrap(~ Model, scales = &quot;free_y&quot;)</code></pre>
<pre><code>#&gt; Selecting by tf_idf</code></pre>
<p><img src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/figure-html/tf_idf_graph-1.png" width="100%" /></p>
<p>As we can see, these are the main items that separate one review from the other. Amongst them we can see the main flagship of <strong>Samsung</strong>, especially for latter reviews, they seem to compare the brands quite a lot.</p>
<p>We can also single out that for <strong>One Plus 7 Pro 5G</strong> there is a problem with overheating and the <strong>OnePlus 6</strong> is described as elegant.</p>
<p>Of course, this can be tweaked quite a bit depending on your needs. You can eliminate words, you can replace some of them, or you can add a different grouping to the analysis. I‚Äôm pretty sure you have an idea on what you would change when you apply it to your analytic needs.</p>
</div>
<div id="sentiment-analysis" class="section level1">
<h1>Sentiment Analysis</h1>
<p>Now, finally the good part.</p>
<p>In this segment, I would like to discuss some basic principles of sentiment analysis and how they can be used in data analysis to quickly get an idea about your product. So, how do we achieve that?</p>
<p>Well, the most basic method, and the one that we will cover today, is to simply associate each word in the review to a sentiment. Then it becomes a simple matter of counting how many words are associated with positive or negative sentiments to get the overall affect of the text.</p>
<p>This is quite straight forward and the <code>tidyverse</code> package comes to our aid with some libraries that already have these associations made and are also validated against multiple sources. The libraries are:</p>
<ul>
<li><code>AFFIN</code> from <a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010">Finn √Örup Nielsen</a></li>
<li><code>bing</code> from <a href="https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html">Bing Liu and collaborators</a></li>
<li><code>nrc</code> from <a href="http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm">Saif Mohammad and Peter Turney</a></li>
</ul>
<p>Each of these libraries is helpful in its own way and approaches sentiment analysis differently. Let‚Äôs check them:</p>
<pre class="r"><code>get_sentiments(&quot;afinn&quot;)</code></pre>
<pre><code>#&gt; # A tibble: 2,477 x 2
#&gt;    word       value
#&gt;    &lt;chr&gt;      &lt;dbl&gt;
#&gt;  1 abandon       -2
#&gt;  2 abandoned     -2
#&gt;  3 abandons      -2
#&gt;  4 abducted      -2
#&gt;  5 abduction     -2
#&gt;  6 abductions    -2
#&gt;  7 abhor         -3
#&gt;  8 abhorred      -3
#&gt;  9 abhorrent     -3
#&gt; 10 abhors        -3
#&gt; # ... with 2,467 more rows</code></pre>
<pre class="r"><code>get_sentiments(&quot;bing&quot;)</code></pre>
<pre><code>#&gt; # A tibble: 6,786 x 2
#&gt;    word        sentiment
#&gt;    &lt;chr&gt;       &lt;chr&gt;    
#&gt;  1 2-faces     negative 
#&gt;  2 abnormal    negative 
#&gt;  3 abolish     negative 
#&gt;  4 abominable  negative 
#&gt;  5 abominably  negative 
#&gt;  6 abominate   negative 
#&gt;  7 abomination negative 
#&gt;  8 abort       negative 
#&gt;  9 aborted     negative 
#&gt; 10 aborts      negative 
#&gt; # ... with 6,776 more rows</code></pre>
<pre class="r"><code>get_sentiments(&quot;nrc&quot;)</code></pre>
<pre><code>#&gt; # A tibble: 13,901 x 2
#&gt;    word        sentiment
#&gt;    &lt;chr&gt;       &lt;chr&gt;    
#&gt;  1 abacus      trust    
#&gt;  2 abandon     fear     
#&gt;  3 abandon     negative 
#&gt;  4 abandon     sadness  
#&gt;  5 abandoned   anger    
#&gt;  6 abandoned   fear     
#&gt;  7 abandoned   negative 
#&gt;  8 abandoned   sadness  
#&gt;  9 abandonment anger    
#&gt; 10 abandonment fear     
#&gt; # ... with 13,891 more rows</code></pre>
<p>I want to discuss these libraries just a bit.</p>
<p>The <code>AFINN</code> library gives a score between -5 and +5 to each word. Once this is done, the sentiment can be inferred by summing up the scores.</p>
<p>The <code>bing</code> library simply associates a word with a negative or positive valence. At the end we can count how many words are positive or negative.</p>
<p>The <code>nrc</code> library is interesting because it gives you a list of words that can be classified in multiple ways. As you can see, the second element, can be classified either as <strong>fear</strong>, <strong>negative</strong> or <strong>sadness</strong>. This is useful if you want to check for a specific sentiment, or a list of specific sentiments in a text (<em>e.g.</em> just how many terms are associated with fear)</p>
<p>Let‚Äôs proceed by using the <code>AFINN</code> library to check the sentiment for each model and see how they perform. We will use just the conclusion for each review as that should be the most relevant in transmitting the overall sentiment for the whole review.</p>
<p>However, we have to keep in mind that these being technical reviews, they might contain a terminology different from the one used in natural language, and the analysis might not be as accurate as an analysis on Facebook posts, for example.</p>
<pre class="r"><code>conclusion_afinn &lt;- reviews %&gt;%
  filter(str_detect(Segment, &quot;Conclusion&quot;)) %&gt;%
  unnest_tokens(&quot;Word&quot;, &quot;Text&quot;) %&gt;%
  anti_join(stop_words, by = c(&quot;Word&quot; = &quot;word&quot;)) %&gt;%
# We will get the sentiments with a inner_join since the words that don&#39;t have a match, don&#39;t have a score value
  inner_join(get_sentiments(&quot;afinn&quot;), by = c(&quot;Word&quot; = &quot;word&quot;))

conclusion_afinn</code></pre>
<pre><code>#&gt; # A tibble: 122 x 4
#&gt;    Model     Segment                 Word     value
#&gt;    &lt;chr&gt;     &lt;chr&gt;                   &lt;chr&gt;    &lt;dbl&gt;
#&gt;  1 OnePlus 1 Cameras and Conclusions cut         -1
#&gt;  2 OnePlus 1 Cameras and Conclusions true         2
#&gt;  3 OnePlus 1 Cameras and Conclusions alive        1
#&gt;  4 OnePlus 1 Cameras and Conclusions true         2
#&gt;  5 OnePlus 1 Cameras and Conclusions miss        -2
#&gt;  6 OnePlus 1 Cameras and Conclusions straight     1
#&gt;  7 OnePlus 1 Cameras and Conclusions capable      1
#&gt;  8 OnePlus 1 Cameras and Conclusions free         1
#&gt;  9 OnePlus 1 Cameras and Conclusions demand      -1
#&gt; 10 OnePlus 1 Cameras and Conclusions impress      3
#&gt; # ... with 112 more rows</code></pre>
<p>As you can see, each token has been unnested, and assigned a sentiment value.</p>
<p>Now, in order to check the sentiments for each review, all we need to do is add the scores and plot them.</p>
<pre class="r"><code>conclusion_afinn %&gt;%
  group_by(Model) %&gt;%
  summarise(Score = sum(value)) %&gt;%
  arrange(desc(Score)) %&gt;%
  mutate(Model = factor(Model, levels = rev(unique(Model)))) %&gt;%
  ggplot(mapping = aes(x = Model, y = Score)) +
  geom_col() +
  coord_flip() +
  labs(x = NULL)</code></pre>
<p><img src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/figure-html/conclusions_affin_graph-1.png" width="100%" /></p>
<p>The scores are in and overall the <strong>Oneplus 2</strong> has the best reviews.</p>
<p>However, what if we want to see a report on which model has the most positive and negative reviews? For that we would use the <code>bing</code> library.</p>
<p>Let‚Äôs see how:</p>
<pre class="r"><code>conclusion_bing &lt;- reviews %&gt;%
  filter(str_detect(Segment, &quot;Conclusion&quot;)) %&gt;%
  unnest_tokens(&quot;Word&quot;, &quot;Text&quot;) %&gt;%
  anti_join(stop_words, by = c(&quot;Word&quot; = &quot;word&quot;)) %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;), by = c(&quot;Word&quot; = &quot;word&quot;))

conclusion_bing</code></pre>
<pre><code>#&gt; # A tibble: 189 x 4
#&gt;    Model     Segment                 Word       sentiment
#&gt;    &lt;chr&gt;     &lt;chr&gt;                   &lt;chr&gt;      &lt;chr&gt;    
#&gt;  1 OnePlus 1 Cameras and Conclusions led        positive 
#&gt;  2 OnePlus 1 Cameras and Conclusions distortion negative 
#&gt;  3 OnePlus 1 Cameras and Conclusions miss       negative 
#&gt;  4 OnePlus 1 Cameras and Conclusions dynamic    positive 
#&gt;  5 OnePlus 1 Cameras and Conclusions distortion negative 
#&gt;  6 OnePlus 1 Cameras and Conclusions warped     negative 
#&gt;  7 OnePlus 1 Cameras and Conclusions unnatural  negative 
#&gt;  8 OnePlus 1 Cameras and Conclusions admirable  positive 
#&gt;  9 OnePlus 1 Cameras and Conclusions soft       positive 
#&gt; 10 OnePlus 1 Cameras and Conclusions prefer     positive 
#&gt; # ... with 179 more rows</code></pre>
<p>Now we can proceed with the same steps, just add the sentiment to the grouping.</p>
<pre class="r"><code>conclusion_bing %&gt;%
  group_by(Model, sentiment) %&gt;%
  count() %&gt;%
  ungroup() %&gt;%
  mutate(Model = reorder(Model, n)) %&gt;%
  ggplot(mapping = aes(x = Model, y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(x = NULL, y = &quot;Negative vs positive sentiment / Model&quot;) +
  facet_wrap(~ sentiment, ncol = 2)</code></pre>
<p><img src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/figure-html/conclusions_bing_graph-1.png" width="100%" /></p>
<p>Here we can see a more nuanced approach.</p>
<p>For example, the <strong>OnePlus 6T</strong> and the <strong>OnePlus 7 (for China)</strong> have no negative reviews, but they also have only a few positive things said about them. This seems to be reflected in their placement in the previous graph as well.</p>
<p>A curious case can be for the <strong>OnePlus 3</strong> which seems to have more positive than negative reviews, however as an overall score it is dead last on a positivity ranking. This indicates that the review did not regard this model with high praise or the really negative descriptions were very negative. Most likely a combination of both.</p>
<p>Both these approaches have their advantages and disadvantages and in practice you will most likely use a combination of both, not just one. It is really useful to view a problem from multiple angles. You never know which method is helpful for the decision makers in your company.</p>
<p>With that in mind, I would like to discuss one more method of presenting the data that might help in some situations more than graphs.</p>
<div id="wordclouds" class="section level2">
<h2>WordClouds</h2>
<p>In this section I would like to show you a different approach in presenting the data, <strong>WordClouds</strong>.</p>
<p>I personally find them very useful when you are trying to communicate the prevalence of a word in a text or speech. They basically have the same role as a pie chart, but they‚Äôre way better because they display data in a more user-friendly way. Using a wordcloud will allow you to look at it and see how frequent a word is without having to check and re-check a legend for dozens of times.</p>
<p>With that said, let‚Äôs check our wordcloud. It should show the same data as the first graph, just in a different display style, so I will use the same data set <code>reviews_tidy</code>.</p>
<p>For this I will use the <code>wordcloud</code> package. If you do not have it installed, you can install it by using <code>install.packages("wordcloud")</code>.</p>
<pre class="r"><code>library(wordcloud)
#&gt; Loading required package: RColorBrewer

reviews_tidy %&gt;%
  count(Word) %&gt;%
  with(wordcloud(Word, n, max.words = 100))</code></pre>
<p><img src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/figure-html/wordcloud_overall-1.png" width="100%" /></p>
<p>As you can see, the results are similar to the first analysis, the more frequent a word, the larger the font. However, with this type of graph we can include a lot more items. In this we have included 100 words, as opposed to 15 in the first graph.</p>
<p>Now, this clearly shows that the most prevalent word is <strong>oneplus</strong> followed by <strong>phone</strong> then <strong>pro</strong> and so on, exactly the same information we had before, the only difference is that we have a bigger picture using this method.</p>
<p>As mentioned, it‚Äôs a very useful way to show the prevalence of multiple words in a text.</p>
<p>Now, I would like to show you how you can use a wordcloud for sentiment analysis.</p>
<pre class="r"><code>library(reshape2)
#&gt; 
#&gt; Attaching package: &#39;reshape2&#39;
#&gt; The following object is masked from &#39;package:tidyr&#39;:
#&gt; 
#&gt;     smiths


reviews_tidy %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;), by = c(&quot;Word&quot; = &quot;word&quot;)) %&gt;%
  count(Word, sentiment, sort = TRUE) %&gt;%
  acast(Word ~ sentiment, value.var = &quot;n&quot;, fill = 0) %&gt;%
  comparison.cloud(colors = c(&quot;#202121&quot;, &quot;#797C80&quot;),
                   max.words = 50)</code></pre>
<p><img src="https://www.vladaluas.com/post/text-analysis-with-r/index.en_files/figure-html/wordcloud_sentiment-1.png" width="100%" /></p>
<p>This is a very quick and useful way to show which elements influence the sentiment for your product the most and make decisions based on it.</p>
<p>We can clearly see that the words that influence the most the negative scores are <em>noise</em>, <em>expensive</em> and <em>loud</em> while the ones that influence the positive reviews are <em>excellent</em>, <em>fast</em> and <em>smooth</em>.</p>
</div>
<div id="sentiment-analysis-wrap-up" class="section level2">
<h2>Sentiment Analysis wrap up</h2>
<p>There is more to be said about sentiment analysis, however in this article I just wanted to give you a short introduction and show some basic principles for it.</p>
<p>I‚Äôm sure you have noticed some of the quirks yourself. For example the lexicons we have used here are intended for just one word, and that can miss the sentiment of a phase (<em>e.g.</em> <em>not good</em> is a negative term, however the lexicon will see <em>not</em> as neutral and <em>good</em> as positive, therefore overall it will see it as positive). In order to avoid situations like this we can use pairing of words and check for these types of situation.</p>
<p>I plan to go into more detail in a series of articles on the subject, so if you find something interesting or have a topic to discuss, please let me know.</p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>When I read the book, I realised that this type of analysis is very scalable, if done with a programming language like <code>R</code>. By this I mean that a computer will have no problem in analysing 10 or 30.000 words in about the same time. For a human the difference is huge.</p>
<p>Besides being scalable, this analysis can be done multiple times without having to change the code or spend the time setting everything up.</p>
<p>The last advantage of this is that this method is not prone to human error or fatigue. Let‚Äôs be honest, we as humans get tired after some time spent in the same task, and we can get errors. Why not avoid this if possible?</p>
<p>If you have to do these types of analyses, please let me know if you think this article could be useful in your day to day work, and if you have applied them, please let me know how it influenced your time spent on the analysis.</p>
<p>Also, check <em>Julia</em> and <em>David‚Äôs</em> <a href="https://www.tidytextmining.com/">book</a> and if it helped you and you can afford it, buy it to show your support of their great work.</p>
</div>

    
      
    
  </article>
<aside class="sidebar">
  <section class="sidebar_inner">
    
      <h2>Vlad Aluas</h2>
      <div class="sidebar_description">
        Data Engineer, Data Analyst,  Cognitive Psychologist and all out Opinionated Prick
      </div>
      <a href='https://www.vladaluas.com/about/' class="button mt-1" role="button" title='Read More'>Read More</a>
    <h2 class="mt-4">Recent Posts</h2>
    <ul class="flex-column">
      <li>
        <a href="https://www.vladaluas.com/post/data-cleaning/" class="nav-link" title="Data Cleaning">Data Cleaning</a>
      </li>
      <li>
        <a href="https://www.vladaluas.com/post/code-maintenance/" class="nav-link" title="Code Maintenance">Code Maintenance</a>
      </li>
      <li>
        <a href="https://www.vladaluas.com/post/introduction-to-visuals/" class="nav-link" title="Introduction to Visuals with R">Introduction to Visuals with R</a>
      </li>
      <li>
        <a href="https://www.vladaluas.com/post/github-with-r/" class="nav-link" title="GitHub With R">GitHub With R</a>
      </li>
    </ul>
    <div>
      <h2 class="mt-4 taxonomy" id="categories-section">Categories</h2>
      <nav class="tags_nav">
        <a href='https://www.vladaluas.com/categories/tutorial/' class="post_tag button button_translucent" title="tutorial">
          TUTORIAL
          <span class="button_tally">5</span>
        </a>
        
        
      </nav>
    </div>
    <div>
      <h2 class="mt-4 taxonomy" id="series-section">Series</h2>
      <nav class="tags_nav">
        <a href='https://www.vladaluas.com/series/tutorials/' class="post_tag button button_translucent" title="tutorials">
          TUTORIALS
          <span class="button_tally">3</span>
        </a>
        
        
      </nav>
    </div>
    <div>
      <h2 class="mt-4 taxonomy" id="tags-section">Tags</h2>
      <nav class="tags_nav">
        <a href='https://www.vladaluas.com/tags/r/' class="post_tag button button_translucent" title="r">
          R
          <span class="button_tally">5</span>
        </a>
        
        <a href='https://www.vladaluas.com/tags/tidyverse/' class="post_tag button button_translucent" title="tidyverse">
          TIDYVERSE
          <span class="button_tally">2</span>
        </a>
        
        <a href='https://www.vladaluas.com/tags/code-mainetnance/' class="post_tag button button_translucent" title="code-mainetnance">
          CODE-MAINETNANCE
          <span class="button_tally">1</span>
        </a>
        
        <a href='https://www.vladaluas.com/tags/data-cleaning/' class="post_tag button button_translucent" title="data-cleaning">
          DATA-CLEANING
          <span class="button_tally">1</span>
        </a>
        
        <a href='https://www.vladaluas.com/tags/ggplot2/' class="post_tag button button_translucent" title="ggplot2">
          GGPLOT2
          <span class="button_tally">1</span>
        </a>
        
        <a href='https://www.vladaluas.com/tags/github/' class="post_tag button button_translucent" title="github">
          GITHUB
          <span class="button_tally">1</span>
        </a>
        
        <a href='https://www.vladaluas.com/tags/plot/' class="post_tag button button_translucent" title="plot">
          PLOT
          <span class="button_tally">1</span>
        </a>
        
        <a href='https://www.vladaluas.com/tags/text-analysis/' class="post_tag button button_translucent" title="text-analysis">
          TEXT-ANALYSIS
          <span class="button_tally">1</span>
        </a>
        
        <a href='https://www.vladaluas.com/tags/tidytext/' class="post_tag button button_translucent" title="tidytext">
          TIDYTEXT
          <span class="button_tally">1</span>
        </a>
        
        
      </nav>
    </div>
  </section>
</aside>

  
</div>
    </main><svg width="0" height="0" class="hidden">
  <symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="facebook">
    <path d="M437 0H75C33.648 0 0 33.648 0 75v362c0 41.352 33.648 75 75 75h151V331h-60v-90h60v-61c0-49.629 40.371-90 90-90h91v90h-91v61h91l-15 90h-76v181h121c41.352 0 75-33.648 75-75V75c0-41.352-33.648-75-75-75zm0 0"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18.001 18.001" id="twitter">
    <path d="M15.891 4.013c.808-.496 1.343-1.173 1.605-2.034a8.68 8.68 0 0 1-2.351.861c-.703-.756-1.593-1.14-2.66-1.14-1.043 0-1.924.366-2.643 1.078a3.56 3.56 0 0 0-1.076 2.605c0 .309.039.585.117.819-3.076-.105-5.622-1.381-7.628-3.837-.34.601-.51 1.213-.51 1.846 0 1.301.549 2.332 1.645 3.089-.625-.053-1.176-.211-1.645-.47 0 .929.273 1.705.82 2.388a3.623 3.623 0 0 0 2.115 1.291c-.312.08-.641.118-.979.118-.312 0-.533-.026-.664-.083.23.757.664 1.371 1.291 1.841a3.652 3.652 0 0 0 2.152.743C4.148 14.173 2.625 14.69.902 14.69c-.422 0-.721-.006-.902-.038 1.697 1.102 3.586 1.649 5.676 1.649 2.139 0 4.029-.542 5.674-1.626 1.645-1.078 2.859-2.408 3.639-3.974a10.77 10.77 0 0 0 1.172-4.892v-.468a7.788 7.788 0 0 0 1.84-1.921 8.142 8.142 0 0 1-2.11.593z"
      ></path>
  </symbol>
  <symbol aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="mail">
    <path  d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="calendar">
    <path d="M452 40h-24V0h-40v40H124V0H84v40H60C26.916 40 0 66.916 0 100v352c0 33.084 26.916 60 60 60h392c33.084 0 60-26.916 60-60V100c0-33.084-26.916-60-60-60zm20 412c0 11.028-8.972 20-20 20H60c-11.028 0-20-8.972-20-20V188h432v264zm0-304H40v-48c0-11.028 8.972-20 20-20h24v40h40V80h264v40h40V80h24c11.028 0 20 8.972 20 20v48z"></path>
    <path d="M76 230h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zM76 310h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zM76 390h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zm80-80h40v40h-40z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="github">
    <path d="M255.968 5.329C114.624 5.329 0 120.401 0 262.353c0 113.536 73.344 209.856 175.104 243.872 12.8 2.368 17.472-5.568 17.472-12.384 0-6.112-.224-22.272-.352-43.712-71.2 15.52-86.24-34.464-86.24-34.464-11.616-29.696-28.416-37.6-28.416-37.6-23.264-15.936 1.728-15.616 1.728-15.616 25.696 1.824 39.2 26.496 39.2 26.496 22.848 39.264 59.936 27.936 74.528 21.344 2.304-16.608 8.928-27.936 16.256-34.368-56.832-6.496-116.608-28.544-116.608-127.008 0-28.064 9.984-51.008 26.368-68.992-2.656-6.496-11.424-32.64 2.496-68 0 0 21.504-6.912 70.4 26.336 20.416-5.696 42.304-8.544 64.096-8.64 21.728.128 43.648 2.944 64.096 8.672 48.864-33.248 70.336-26.336 70.336-26.336 13.952 35.392 5.184 61.504 2.56 68 16.416 17.984 26.304 40.928 26.304 68.992 0 98.72-59.84 120.448-116.864 126.816 9.184 7.936 17.376 23.616 17.376 47.584 0 34.368-.32 62.08-.32 70.496 0 6.88 4.608 14.88 17.6 12.352C438.72 472.145 512 375.857 512 262.353 512 120.401 397.376 5.329 255.968 5.329z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 212 212" id="gitlab">
    <path d="M12.3 74.7h54L43.3 3c-1-3.6-6.4-3.6-7.6 0L12.3 74.8z" />
    <path d="M12.3 74.7L.5 111c-1 3.2 0 6.8 3 8.8l101.6 74-92.5-119z"/>
    <path d="M105 193.7l-38.6-119h-54l92.7 119z"/>
    <path d="M105 193.7l38.7-119H66.4l38.7 119z"/>
    <path d="M105 193.7l38.7-119H198l-93 119z"/>
    <path d="M198 74.7l11.6 36.2c1 3 0 6.6-3 8.6l-101.5 74 93-119z"/>
    <path d="M198 74.7h-54.3L167 3c1.2-3.6 6.4-3.6 7.6 0L198 74.8z"/> 
  </symbol>
  <symbol viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="rss">
    <circle cx="3.429" cy="20.571" r="3.429"></circle>
    <path d="M11.429 24h4.57C15.999 15.179 8.821 8.001 0 8v4.572c6.302.001 11.429 5.126 11.429 11.428z"></path>
    <path d="M24 24C24 10.766 13.234 0 0 0v4.571c10.714 0 19.43 8.714 19.43 19.429z"></path>
  </symbol>
  <symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="linkedin">
    <path d="M437 0H75C33.648 0 0 33.648 0 75v362c0 41.352 33.648 75 75 75h362c41.352 0 75-33.648 75-75V75c0-41.352-33.648-75-75-75zM181 406h-60V196h60zm0-240h-60v-60h60zm210 240h-60V286c0-16.54-13.46-30-30-30s-30 13.46-30 30v120h-60V196h60v11.309C286.719 202.422 296.93 196 316 196c40.691.043 75 36.547 75 79.688zm0 0"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 612 612" id="arrow">
    <path d="M604.501 440.509L325.398 134.956c-5.331-5.357-12.423-7.627-19.386-7.27-6.989-.357-14.056 1.913-19.387 7.27L7.499 440.509c-9.999 10.024-9.999 26.298 0 36.323s26.223 10.024 36.222 0l262.293-287.164L568.28 476.832c9.999 10.024 26.222 10.024 36.221 0 9.999-10.023 9.999-26.298 0-36.323z"></path>
  </symbol>
  <symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="carly">
    <path d="M504.971 239.029L448 182.059V84c0-46.317-37.682-84-84-84h-44c-13.255 0-24 10.745-24 24s10.745 24 24 24h44c19.851 0 36 16.149 36 36v108c0 6.365 2.529 12.47 7.029 16.971L454.059 256l-47.029 47.029A24.002 24.002 0 0 0 400 320v108c0 19.851-16.149 36-36 36h-44c-13.255 0-24 10.745-24 24s10.745 24 24 24h44c46.318 0 84-37.683 84-84v-98.059l56.971-56.971c9.372-9.372 9.372-24.568 0-33.941zM112 192V84c0-19.851 16.149-36 36-36h44c13.255 0 24-10.745 24-24S205.255 0 192 0h-44c-46.318 0-84 37.683-84 84v98.059l-56.971 56.97c-9.373 9.373-9.373 24.568 0 33.941L64 329.941V428c0 46.317 37.682 84 84 84h44c13.255 0 24-10.745 24-24s-10.745-24-24-24h-44c-19.851 0-36-16.149-36-36V320c0-6.365-2.529-12.47-7.029-16.971L57.941 256l47.029-47.029A24.002 24.002 0 0 0 112 192z"></path>
  </symbol>
  <symbol viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="copy">
    <path d="M23 2.75A2.75 2.75 0 0 0 20.25 0H8.75A2.75 2.75 0 0 0 6 2.75v13.5A2.75 2.75 0 0 0 8.75 19h11.5A2.75 2.75 0 0 0 23 16.25zM18.25 14.5h-7.5a.75.75 0 0 1 0-1.5h7.5a.75.75 0 0 1 0 1.5zm0-3h-7.5a.75.75 0 0 1 0-1.5h7.5a.75.75 0 0 1 0 1.5zm0-3h-7.5a.75.75 0 0 1 0-1.5h7.5a.75.75 0 0 1 0 1.5z"></path>
    <path d="M8.75 20.5a4.255 4.255 0 0 1-4.25-4.25V2.75c0-.086.02-.166.025-.25H3.75A2.752 2.752 0 0 0 1 5.25v16A2.752 2.752 0 0 0 3.75 24h12a2.752 2.752 0 0 0 2.75-2.75v-.75z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512.001 512.001" id="closeme">
    <path d="M284.286 256.002L506.143 34.144c7.811-7.811 7.811-20.475 0-28.285-7.811-7.81-20.475-7.811-28.285 0L256 227.717 34.143 5.859c-7.811-7.811-20.475-7.811-28.285 0-7.81 7.811-7.811 20.475 0 28.285l221.857 221.857L5.858 477.859c-7.811 7.811-7.811 20.475 0 28.285a19.938 19.938 0 0 0 14.143 5.857 19.94 19.94 0 0 0 14.143-5.857L256 284.287l221.857 221.857c3.905 3.905 9.024 5.857 14.143 5.857s10.237-1.952 14.143-5.857c7.811-7.811 7.811-20.475 0-28.285L284.286 256.002z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="open-menu">
    <path d="M492 236H20c-11.046 0-20 8.954-20 20s8.954 20 20 20h472c11.046 0 20-8.954 20-20s-8.954-20-20-20zm0-160H20C8.954 76 0 84.954 0 96s8.954 20 20 20h472c11.046 0 20-8.954 20-20s-8.954-20-20-20zm0 320H20c-11.046 0-20 8.954-20 20s8.954 20 20 20h472c11.046 0 20-8.954 20-20s-8.954-20-20-20z"></path>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="instagram">
    <path d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"/>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id=youtube>
    <path d="M19.615 3.184c-3.604-.246-11.631-.245-15.23 0-3.897.266-4.356 2.62-4.385 8.816.029 6.185.484 8.549 4.385 8.816 3.6.245 11.626.246 15.23 0 3.897-.266 4.356-2.62 4.385-8.816-.029-6.185-.484-8.549-4.385-8.816zm-10.615 12.816v-8l8 3.993-8 4.007z"/>
  </symbol>
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="stackoverflow">
    <path d="M21 27v-8h3v11H0V19h3v8h18z"></path><path d="M17.1.2L15 1.8l7.9 10.6 2.1-1.6L17.1.2zm3.7 14.7L10.6 6.4l1.7-2 10.2 8.5-1.7 2zM7.2 12.3l12 5.6 1.1-2.4-12-5.6-1.1 2.4zm-1.8 6.8l13.56 1.96.17-2.38-13.26-2.55-.47 2.97zM19 25H5v-3h14v3z"></path>
  </symbol>
</svg>


  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<footer class="footer">
  <div class="footer_inner wrap pale">
    <img src='https://www.vladaluas.com/icons/apple-touch-icon.png' class="icon icon_2 transparent" alt="Clarity">
    <p>Copyright&nbsp;<span class="year"></span>&nbsp;CLARITY. All Rights Reserved</p><a class="to_top" href="#documentTop">
  <svg class="icon">
  <use xlink:href="#arrow"></use>
</svg>
</a>

  </div>
</footer>

    <script type="text/javascript" src="https://www.vladaluas.com/js/bundle.min.d9c61e439fe5301e875d687a930ef57eb7e61e43791740d42a373b51acdb4b76c8a13828486c9b18aeccd221941642bcbf68a751076c32b08f874a64cf11d7f0.js" integrity="sha512-2cYeQ5/lMB6HXWh6kw71frfmHkN5F0DUKjc7UazbS3bIoTgoSGybGK7M0iGUFkK8v2inUQdsMrCPh0pkzxHX8A==" crossorigin="anonymous"></script>
    
  </body>
</html>
